{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7c49be-3341-458b-8b86-187fe8b3dee5",
   "metadata": {},
   "source": [
    "### 預測 (response ： proline )###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9014653-8bd9-454a-9716-f0383e4c809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 載入資料集\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = X.pop('proline')  # 將 'proline' 設為 y，並從 X 中移除\n",
    "\n",
    "# Train：120 samples,  Test：30 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86791023-46d2-48b7-95d5-ecfa5703728e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
       "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
       "       'proanthocyanins', 'color_intensity', 'hue',\n",
       "       'od280/od315_of_diluted_wines'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9f464ec-f910-47a6-97cb-59bbe8b7dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1065.0\n",
       "1      1050.0\n",
       "2      1185.0\n",
       "3      1480.0\n",
       "4       735.0\n",
       "        ...  \n",
       "173     740.0\n",
       "174     750.0\n",
       "175     835.0\n",
       "176     840.0\n",
       "177     560.0\n",
       "Name: proline, Length: 178, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ebd2720-8539-4357-b363-a369f2d698a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "137    12.53        5.51  2.64               25.0       96.0           1.79   \n",
       "98     12.37        1.07  2.10               18.5       88.0           3.52   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "38     13.07        1.50  2.10               15.5       98.0           2.40   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "71     13.86        1.51  2.67               25.0       86.0           2.95   \n",
       "106    12.25        1.73  2.12               19.0       80.0           1.65   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "92     12.69        1.53  2.26               20.7       80.0           1.38   \n",
       "102    12.34        2.45  2.46               21.0       98.0           2.56   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "158        1.31                  0.53             2.70            13.00  0.57   \n",
       "137        0.60                  0.63             1.10             5.00  0.82   \n",
       "98         3.75                  0.24             1.95             4.50  1.04   \n",
       "159        1.10                  0.52             2.29            11.75  0.57   \n",
       "38         2.64                  0.28             1.37             3.70  1.18   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "71         2.86                  0.21             1.87             3.38  1.36   \n",
       "106        2.03                  0.37             1.63             3.40  1.00   \n",
       "14         3.64                  0.29             2.96             7.50  1.20   \n",
       "92         1.46                  0.58             1.62             3.05  0.96   \n",
       "102        2.11                  0.34             1.31             2.80  0.80   \n",
       "\n",
       "     od280/od315_of_diluted_wines  \n",
       "158                          1.96  \n",
       "137                          1.69  \n",
       "98                           2.77  \n",
       "159                          1.78  \n",
       "38                           2.69  \n",
       "..                            ...  \n",
       "71                           3.16  \n",
       "106                          3.17  \n",
       "14                           3.00  \n",
       "92                           2.06  \n",
       "102                          3.38  \n",
       "\n",
       "[142 rows x 12 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed87e706-6e43-47f7-a0b4-a33351e26e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33605.46474640111 0.6297159110420931\n",
      "42923.17111441044 0.6614362470640591\n"
     ]
    }
   ],
   "source": [
    "# (a) 簡單線性回歸\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "print(mean_squared_error(y_train, lr_pred_train), r2_score(y_train, lr_pred_train))\n",
    "print(mean_squared_error(y_test, lr_pred_test), r2_score(y_test, lr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5a716d2-cfbd-44d3-be65-e69fa9f70953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4671.388837323942 0.9485279857651165\n",
      "29218.061725000003 0.7695376093075075\n"
     ]
    }
   ],
   "source": [
    "# (c) 隨機森林\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "print(mean_squared_error(y_train, rf_pred_train), r2_score(y_train, rf_pred_train))\n",
    "print(mean_squared_error(y_test, rf_pred_test), r2_score(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e95c4849-d74b-4048-a979-cef6ad9f45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 14) (36, 14)\n"
     ]
    }
   ],
   "source": [
    "X_train_new = np.column_stack((X_train, lr_pred_train, rf_pred_train))\n",
    "\n",
    "X_test_new = np.column_stack((X_test, lr_pred_test, rf_pred_test))\n",
    "\n",
    "print(X_train_new.shape, X_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1b8e0ee-6585-41b8-9615-097b01d3e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.43400000e+01, 1.68000000e+00, 2.70000000e+00, ...,\n",
       "        1.96000000e+00, 9.28851360e+02, 6.66720000e+02],\n",
       "       [1.25300000e+01, 5.51000000e+00, 2.64000000e+00, ...,\n",
       "        1.69000000e+00, 3.99616957e+02, 5.90990000e+02],\n",
       "       [1.23700000e+01, 1.07000000e+00, 2.10000000e+00, ...,\n",
       "        2.77000000e+00, 6.84260769e+02, 6.54010000e+02],\n",
       "       ...,\n",
       "       [1.43800000e+01, 1.87000000e+00, 2.38000000e+00, ...,\n",
       "        3.00000000e+00, 1.30629850e+03, 1.42795000e+03],\n",
       "       [1.26900000e+01, 1.53000000e+00, 2.26000000e+00, ...,\n",
       "        2.06000000e+00, 4.85207865e+02, 4.98670000e+02],\n",
       "       [1.23400000e+01, 2.45000000e+00, 2.46000000e+00, ...,\n",
       "        3.38000000e+00, 5.92828382e+02, 4.71610000e+02]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3780fc59-8712-4449-b605-5d001cac265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963.6386276428825 0.9783635148102761\n",
      "25739.820788267607 0.7969728214454147\n"
     ]
    }
   ],
   "source": [
    "# 5. 用新特徵進行最終預測(LM)\n",
    "final_model_lm = LinearRegression()\n",
    "final_model_lm.fit(X_train_new, y_train)\n",
    "final_pred_train_lm = final_model_lm.predict(X_train_new)\n",
    "final_pred_test_lm = final_model_lm.predict(X_test_new)\n",
    "\n",
    "# 6. 評估模型表現\n",
    "print(mean_squared_error(y_train, final_pred_train_lm), r2_score(y_train, final_pred_train_lm))\n",
    "print(mean_squared_error(y_test, final_pred_test_lm), r2_score(y_test, final_pred_test_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ee8dba2-d57b-42f1-83a0-3a51a05f7acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556.3490028169016 0.9938698308383681\n",
      "27689.960047222223 0.7815907690686338\n"
     ]
    }
   ],
   "source": [
    "# 5. 用新特徵進行最終預測(RF)\n",
    "final_model_rf = RandomForestRegressor(random_state=42)\n",
    "final_model_rf.fit(X_train_new, y_train)\n",
    "final_pred_train_rf = final_model_rf.predict(X_train_new)\n",
    "final_pred_test_rf = final_model_rf.predict(X_test_new)\n",
    "\n",
    "# 6. 評估模型表現\n",
    "print(mean_squared_error(y_train, final_pred_train_rf), r2_score(y_train, final_pred_train_rf))\n",
    "print(mean_squared_error(y_test, final_pred_test_rf), r2_score(y_test, final_pred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5863d9-3729-45d1-8b2c-6e306ab03f61",
   "metadata": {},
   "source": [
    "### 分類 (response ： class )###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e033d0ec-c64c-4dfa-abfa-d6afdf5a60d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.69\n",
      "Random Forest Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定義參數網格\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"class\")\n",
    "\n",
    "# 切分資料集：Train (80%) 和 Test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# 定義模型\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Support Vector Machine\": GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=3),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 訓練與評估\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # 訓練模型\n",
    "    y_pred = model.predict(X_test)  # 預測\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 計算準確率\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "482c2c14-c067-4e99-a233-ed180246e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    2\n",
       "174    2\n",
       "175    2\n",
       "176    2\n",
       "177    2\n",
       "Name: class, Length: 178, dtype: int32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c682236-45e7-4752-9754-88a23f7197ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Stacking Model Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# 載入資料集\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"class\")\n",
    "\n",
    "# 切分資料集：Train (80%) 和 Test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# 定義基模型（第一層模型）\n",
    "base_models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=200, random_state=42)),\n",
    "    (\"Support Vector Machine\", SVC(probability=True, random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# 初始化空列表儲存基模型的預測\n",
    "meta_train = []  # 用於存儲訓練集的新特徵\n",
    "meta_test = []   # 用於存儲測試集的新特徵\n",
    "\n",
    "# 訓練基模型並生成新特徵\n",
    "for model_name, model in base_models:\n",
    "    # 訓練基模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 對訓練集生成預測概率 (每列為一個類別的概率)\n",
    "    train_preds = model.predict_proba(X_train)\n",
    "    meta_train.append(train_preds)\n",
    "    \n",
    "    # 對測試集生成預測概率\n",
    "    test_preds = model.predict_proba(X_test)\n",
    "    meta_test.append(test_preds)\n",
    "\n",
    "# 將所有基模型的預測結果水平拼接成新的特徵矩陣\n",
    "meta_train = np.hstack(meta_train)\n",
    "meta_test = np.hstack(meta_test)\n",
    "\n",
    "# 將原始特徵與堆疊特徵結合\n",
    "X_train_full = np.hstack([X_train, meta_train])\n",
    "X_test_full = np.hstack([X_test, meta_test])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定義參數網格\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# 使用 GridSearchCV 找最佳參數\n",
    "grid = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=3)\n",
    "grid.fit(X_train_full, y_train)\n",
    "\n",
    "# 使用最佳參數進行訓練\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test_full)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SVC Stacking Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ed4a73b-9e78-48ca-b1c5-a4d807c34d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selected Stacking Model Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# 使用隨機森林進行特徵重要性分析\n",
    "selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "selector.fit(X_train_full, y_train)\n",
    "\n",
    "# 提取特徵重要性並篩選重要特徵\n",
    "feature_importances = selector.feature_importances_\n",
    "threshold = np.sort(feature_importances)[-10]  # 保留前 10 個特徵\n",
    "selected_features = feature_importances >= threshold\n",
    "\n",
    "X_train_selected = X_train_full[:, selected_features]\n",
    "X_test_selected = X_test_full[:, selected_features]\n",
    "\n",
    "# 使用篩選後的特徵進行 GridSearchCV\n",
    "grid.fit(X_train_selected, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Feature Selected Stacking Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0207a067-aa74-4c7b-baea-cde5399cc108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True, False, False,\n",
       "        True, False,  True, False,  True,  True,  True, False, False,\n",
       "       False,  True,  True,  True])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "58babf6e-7e81-47e7-9d0d-a5be4ef6ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.19</td>\n",
       "      <td>3.13</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>11.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.58</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.08</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>12.60</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.90</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.77</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>12.16</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.31</td>\n",
       "      <td>22.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.26</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.16</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.06</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "79     12.70        3.87  2.40               23.0      101.0           2.83   \n",
       "84     11.84        0.89  2.58               18.0       94.0           2.20   \n",
       "39     14.22        3.99  2.51               13.2      128.0           3.00   \n",
       "101    12.60        1.34  1.90               18.5       88.0           1.45   \n",
       "86     12.16        1.61  2.31               22.8       90.0           1.78   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "71     13.86        1.51  2.67               25.0       86.0           2.95   \n",
       "106    12.25        1.73  2.12               19.0       80.0           1.65   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "92     12.69        1.53  2.26               20.7       80.0           1.38   \n",
       "102    12.34        2.45  2.46               21.0       98.0           2.56   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "79         2.55                  0.43             1.95             2.57  1.19   \n",
       "84         2.21                  0.22             2.35             3.05  0.79   \n",
       "39         3.04                  0.20             2.08             5.10  0.89   \n",
       "101        1.36                  0.29             1.35             2.45  1.04   \n",
       "86         1.69                  0.43             1.56             2.45  1.33   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "71         2.86                  0.21             1.87             3.38  1.36   \n",
       "106        2.03                  0.37             1.63             3.40  1.00   \n",
       "14         3.64                  0.29             2.96             7.50  1.20   \n",
       "92         1.46                  0.58             1.62             3.05  0.96   \n",
       "102        2.11                  0.34             1.31             2.80  0.80   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "79                           3.13    463.0  \n",
       "84                           3.08    520.0  \n",
       "39                           3.53    760.0  \n",
       "101                          2.77    562.0  \n",
       "86                           2.26    495.0  \n",
       "..                            ...      ...  \n",
       "71                           3.16    410.0  \n",
       "106                          3.17    510.0  \n",
       "14                           3.00   1547.0  \n",
       "92                           2.06    495.0  \n",
       "102                          3.38    438.0  \n",
       "\n",
       "[89 rows x 13 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9e1f4-5557-4096-8051-2c848f027697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
